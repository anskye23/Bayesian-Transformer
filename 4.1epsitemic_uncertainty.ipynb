{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07igxK-iPT4C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset\n",
        "# from transformers import BertModel, BertTokenizer\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ1LNEXAPrvn"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "num_samples = 10\n",
        "learning_rate = 0.0005  # learning rate for the gradient descent optimizer, related to the step size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xj8ZCAKgron",
        "outputId": "973bb3e2-ec8e-4634-d40b-1d84e2226d1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Reusing dataset tweet_eval (./data_cache_/tweet_eval/irony/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset with 2862 instances loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Reusing dataset tweet_eval (./data_cache_/tweet_eval/irony/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation dataset with 955 instances loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Reusing dataset tweet_eval (./data_cache_/tweet_eval/irony/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test dataset with 784 instances loaded\n"
          ]
        }
      ],
      "source": [
        "# load the \"irony\" dataset(name=irony)\n",
        "cache_dir = \"./data_cache_\"\n",
        "subset_name = \"irony\"\n",
        "\n",
        "train_dataset_ = load_dataset(\n",
        "    \"tweet_eval\",\n",
        "    name=subset_name,\n",
        "    split=\"train\",\n",
        "    ignore_verifications=True,\n",
        "    cache_dir=cache_dir,\n",
        ")\n",
        "print(f\"Training dataset with {len(train_dataset_)} instances loaded\")\n",
        "\n",
        "val_dataset_ = load_dataset(\n",
        "    \"tweet_eval\",\n",
        "    name=subset_name,\n",
        "    split=\"validation\",\n",
        "    ignore_verifications=True,\n",
        "    cache_dir=cache_dir,\n",
        ")\n",
        "print(f\"Validation dataset with {len(val_dataset_)} instances loaded\")\n",
        "\n",
        "test_dataset_ = load_dataset(\n",
        "    \"tweet_eval\",\n",
        "    name=subset_name,\n",
        "    split=\"test\",\n",
        "    ignore_verifications=True,\n",
        "    cache_dir=cache_dir,\n",
        ")\n",
        "print(f\"Test dataset with {len(test_dataset_)} instances loaded\")\n",
        "\n",
        "num_classes_ = np.unique(train_dataset_['label']).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "a43008a5558c429abf86ab5fd5317c06",
            "b7093d323fb64902b877b687871c5fee",
            "0993f5ff72d04b4ab5c840cac074e786",
            "c07d6bdded8349469579f919c754fc07",
            "4b365143a5fc446fa674e14944c75fdb",
            "c82ba162b98741ee819231c8008e4058",
            "6bdf383fd81e4cc48af920529b80ce31",
            "5d0fc4caed6041d39b4c8f57b0c6dc5d",
            "95b5aabde8f5497c8930695ab3bd4a7c",
            "6ef4032ca64549e49e5d03524202e882",
            "7e1c67c368b34a03bc23f39b5b9779b3"
          ]
        },
        "id": "pGtJBPs8gwxB",
        "outputId": "fa8743b7-3219-4be8-d118-c38dc84c3b53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at ./data_cache_/tweet_eval/irony/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/cache-4f5cdcd09d3e61f8.arrow\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a43008a5558c429abf86ab5fd5317c06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at ./data_cache_/tweet_eval/irony/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/cache-cfb0ef38bfeda9c9.arrow\n"
          ]
        }
      ],
      "source": [
        "# create Tokenizer object\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# create 'input_ids', 'token_type_ids', 'attention_mask' for train/val/test dataset\n",
        "def tokenize_function(dataset):\n",
        "    model_inputs = tokenizer(dataset['text'], padding=\"max_length\", max_length=100, truncation=True)\n",
        "    return model_inputs\n",
        "\n",
        "train_dataset_ = train_dataset_.map(tokenize_function, batched=True)\n",
        "val_dataset_ = val_dataset_.map(tokenize_function, batched=True)\n",
        "test_dataset_ = test_dataset_.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNN_w2DIgxQB"
      },
      "outputs": [],
      "source": [
        "# convert dataset to dataloader\n",
        "def convert_to_data_loader(dataset, num_classes):\n",
        "    # convert from list to tensor\n",
        "    input_tensor = torch.from_numpy(np.array(dataset['input_ids']))\n",
        "    label_tensor = torch.from_numpy(np.array(dataset['label'])).long()\n",
        "    # 'attention_mask' is also taken into consideration when constructing DataLoader(def forward())\n",
        "    atten_tensor = torch.from_numpy(np.array(dataset['attention_mask']))\n",
        "    \n",
        "    tensor_dataset = TensorDataset(input_tensor, atten_tensor, label_tensor)\n",
        "    loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return loader\n",
        "\n",
        "# get all sentences ready for the model\n",
        "train_loader = convert_to_data_loader(train_dataset_, num_classes_)\n",
        "val_loader = convert_to_data_loader(val_dataset_, num_classes_)\n",
        "test_loader = convert_to_data_loader(test_dataset_, num_classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDgMJIyCg0Zl"
      },
      "source": [
        "模型部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCUwppIXgzOv"
      },
      "outputs": [],
      "source": [
        "class RoBertaClassifier(nn.Module):\n",
        "    def __init__(self, freeze_bert, aleatoric_use, num_labels):\n",
        "        super(RoBertaClassifier, self).__init__()\n",
        "\n",
        "        # use the pretrained bert model corresponding to the previous tokenizer\n",
        "        self.aleatoric_use = aleatoric_use\n",
        "        # self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert = AutoModel.from_pretrained(\"roberta-base\")\n",
        "        self.config = self.bert.config\n",
        "        \"\"\"\n",
        "        \"_name_or_path\": \"roberta-base\",\n",
        "        \"architectures\": [\"RobertaForMaskedLM\"],\n",
        "        \"attention_probs_dropout_prob\": 0.1,\n",
        "        \"bos_token_id\": 0,\n",
        "        \"classifier_dropout\": null,\n",
        "        \"eos_token_id\": 2,\n",
        "        \"hidden_act\": \"gelu\",\n",
        "        \"hidden_dropout_prob\": 0.1,\n",
        "        \"hidden_size\": 768,\n",
        "        \"initializer_range\": 0.02,\n",
        "        \"intermediate_size\": 3072,\n",
        "        \"layer_norm_eps\": 1e-05,\n",
        "        \"max_position_embeddings\": 514,\n",
        "        \"model_type\": \"roberta\",\n",
        "        \"num_attention_heads\": 12,\n",
        "        \"num_hidden_layers\": 12,\n",
        "        \"pad_token_id\": 1,\n",
        "        \"position_embedding_type\": \"absolute\",\n",
        "        \"transformers_version\": \"4.21.0\",\n",
        "        \"type_vocab_size\": 1,\n",
        "        \"use_cache\": true,\n",
        "        \"vocab_size\": 50265\n",
        "        \"\"\"\n",
        "        # specify the parameter for the classifier\n",
        "        n_input = self.config.hidden_size\n",
        "        n_hidden = 50\n",
        "        p_ = 0.2\n",
        "\n",
        "        # add dense layers to act as the classifier\n",
        "        self.classifier = nn.Linear(n_input, n_hidden)\n",
        "\n",
        "        self.predict = torch.nn.Linear(n_hidden, num_labels)   # predicted output\n",
        "        self.get_var = torch.nn.Linear(n_hidden, num_labels)   # predicted variance\n",
        "\n",
        "        # execute when freeze_bert=True\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = True\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # get the outputs of the roberta model\n",
        "        bert_outputs = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
        "\n",
        "        # extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_outputs = bert_outputs[0][:,0,:]\n",
        "\n",
        "        # Feed input to classifier to compute results(one number for each class)\n",
        "        x = last_hidden_state_outputs  # 64*768\n",
        "        x = self.classifier(x)  # 64*50\n",
        "        x = F.relu(x)  # 64*50\n",
        "        x = F.dropout(x, p=0.2)  # 64*50\n",
        "        \n",
        "        logits = self.predict(x)  # logits layer 64*2\n",
        "        if self.aleatoric_use:  # consider aleatoric uncertainty --> two sets of output\n",
        "          sigma = self.get_var(x)  # uncertainty layer 64*2\n",
        "          return logits, sigma\n",
        "        else:\n",
        "          return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzv1AIjHh5zb",
        "outputId": "e7f24271-9aa1-43ac-fd18-40f077c748de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RoBertaClassifier(\n",
              "  (bert): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=50, bias=True)\n",
              "  (predict): Linear(in_features=50, out_features=2, bias=True)\n",
              "  (get_var): Linear(in_features=50, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model epistemic uncertainty\n",
        "model_epis = RoBertaClassifier(freeze_bert=True, aleatoric_use=False, num_labels=num_classes_)\n",
        "model_epis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9NzsPbYYKjq"
      },
      "outputs": [],
      "source": [
        "def aleatoric_loss_function(labels, pred_y, sigma):\n",
        "\n",
        "  N = labels.size(0)\n",
        "  logvar = torch.log(sigma**2)\n",
        "  loss = torch.sum(0.5*(torch.exp((-1)*logvar)) * (labels - pred_y)**2 + 0.5*logvar)\n",
        "  loss = loss/N\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2a0WmnBY10K"
      },
      "outputs": [],
      "source": [
        "def apply_dropout(m):\n",
        "  if type(m) == F.dropout:  # type(m) == nn.Dropout or\n",
        "    m.train()\n",
        "\n",
        "# net.eval()\n",
        "# net.apply(apply_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG4E0KE70ovN"
      },
      "outputs": [],
      "source": [
        "def train_epistemic(num_epochs, model, train_dataloader, dev_dataloader):  \n",
        "\n",
        "    # loss_fn = nn.CrossEntropyLoss()  # = softmax+NLLLOSS\n",
        "    loss_fn = nn.NLLLoss()  # create loss function object\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # create the optimizer\n",
        "    \n",
        "    # Store the data for plotting\n",
        "    X = []\n",
        "    train_losses_set = []\n",
        "    train_accuracy_set = []\n",
        "    dev_losses_set = []\n",
        "    dev_accuracy_set = []\n",
        "    train_uncertainty_set = []\n",
        "    dev_uncertainty_set = []\n",
        "    \n",
        "    for e in range(num_epochs):\n",
        "        # Track performance on the training set as we are learning...\n",
        "        total_correct = 0\n",
        "        total_trained = 0\n",
        "        train_losses = []\n",
        "        train_epis_uncertainty = []\n",
        "\n",
        "        model.train()  # Put the model in training mode.\n",
        "\n",
        "        # batch_atten(atten_mask) is also used to compute the model output\n",
        "        for i, (batch_input_ids, batch_atten, batch_labels) in enumerate(train_dataloader):\n",
        "\n",
        "            optimizer.zero_grad()  # Reset the optimizer\n",
        "\n",
        "            prob_total = torch.zeros((num_samples, batch_labels.size(0), num_classes_)) # 10*64*2\n",
        "            \n",
        "            # Sample from the model distribution\n",
        "            for t in range(num_samples):\n",
        "              # get the logit output\n",
        "              logit = model(batch_input_ids, batch_atten) # 64*2\n",
        "              # transform the logit into probability\n",
        "              prob_total[t] = F.softmax(logit, dim=1) # 64*2\n",
        "            \n",
        "            # compute the mean over 10 model results: p_c\n",
        "            prob_ave = torch.mean(prob_total, 0)  # 64*2\n",
        "\n",
        "            # Compute the loss for the current batch of data \n",
        "            batch_loss = loss_fn(torch.log(prob_ave), batch_labels) # torch.log()-->ln\n",
        "            batch_epis_uncertainty = torch.mean(torch.sum((-1)*prob_ave*torch.log(prob_ave),dim=1)) # the cross entropy of p_c itself --> epstiemic uncertainty\n",
        "            print(\"my batch_loss:{}\".format(batch_loss))\n",
        "            print(\"batch_epis_uncertainty:{}\".format(batch_epis_uncertainty))\n",
        "\n",
        "            # Perform back propagation to compute the gradients with respect to each weight\n",
        "            batch_loss.backward()\n",
        "\n",
        "            # Update the weights using the compute gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Record the loss from this sample to keep track of progress.\n",
        "            train_losses.append(batch_loss.item())\n",
        "            train_epis_uncertainty.append(batch_epis_uncertainty.item())\n",
        "\n",
        "            # Count correct labels so we can compute accuracy on the training set\n",
        "            pred_y = torch.max(prob_ave, 1)[1].data.numpy()\n",
        "            total_correct += (pred_y == batch_labels.data.numpy()).sum().item()\n",
        "            total_trained += batch_labels.size(0)\n",
        "\n",
        "        train_accuracy = total_correct/total_trained*100\n",
        "\n",
        "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
        "              \"Training Loss: {:.4f}\".format(np.mean(train_losses)),\n",
        "              \"Training Uncertainty: {:.4f}\".format(np.mean(train_epis_uncertainty)),\n",
        "              \"Training Accuracy: {:.4f}%\".format(train_accuracy))\n",
        "        \n",
        "        X.append(e+1)\n",
        "        train_losses_set.append(np.mean(train_losses))\n",
        "        train_accuracy_set.append(train_accuracy)\n",
        "        train_uncertainty_set.append(np.mean(train_epis_uncertainty))  # save but not using\n",
        "\n",
        "        \n",
        "        if e!=4:\n",
        "          continue\n",
        "          \n",
        "        model.eval()  # Switch model to evaluation mode\n",
        "        model.apply(apply_dropout) # Keep the dropout layer open when testing\n",
        "        \n",
        "        total_correct = 0\n",
        "        total_trained = 0\n",
        "        dev_losses = []\n",
        "        dev_epis_uncertainties = []\n",
        "\n",
        "        for dev_input_ids, dev_atten, dev_labels in dev_dataloader:\n",
        "            \n",
        "            dev_prob_total = torch.zeros((num_samples, dev_labels.size(0), num_classes_))\n",
        "\n",
        "            for t in range(num_samples):\n",
        "              dev_logit = model(dev_input_ids,dev_atten)\n",
        "              dev_prob_total[t] = F.softmax(dev_logit, dim=1)\n",
        "            dev_prob_ave = torch.mean(dev_prob_total, 0)\n",
        "\n",
        "            # Compute the loss for the development data\n",
        "            dev_loss = loss_fn(torch.log(dev_prob_ave), dev_labels) # dev_loss computed by cross entropy\n",
        "            dev_epis_uncertainty = torch.mean(torch.sum((-1)*dev_prob_ave*torch.log(dev_prob_ave),dim=1))\n",
        "\n",
        "            # Save the loss on the dev set\n",
        "            dev_losses.append(dev_loss.item())\n",
        "            dev_epis_uncertainties.append(dev_epis_uncertainty.item())\n",
        "\n",
        "            # Count the number of correct predictions\n",
        "            dev_output_y = torch.max(dev_prob_ave, 1)[1].data.numpy()\n",
        "            # predicted_labels = dev_output_y.argmax(1)\n",
        "            total_correct += (dev_output_y == dev_labels.data.numpy()).sum().item()\n",
        "            total_trained += dev_labels.size(0)\n",
        "            \n",
        "        dev_accuracy = total_correct/total_trained*100\n",
        "        \n",
        "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
        "              \"Validation Loss: {:.4f}\".format(np.mean(dev_losses)),\n",
        "              \"Validation Uncertainty: {:.4f}\".format(np.mean(dev_epis_uncertainties)),\n",
        "              \"Validation Accuracy: {:.4f}%\".format(dev_accuracy))\n",
        "        \n",
        "        dev_losses_set.append(np.mean(dev_losses))\n",
        "        dev_accuracy_set.append(dev_accuracy)\n",
        "        dev_uncertainty_set.append(np.mean(dev_epis_uncertainties))  # save but not using\n",
        "    \n",
        "    # Plotting to show the accuracy and loss\n",
        "    plt.figure()\n",
        "    plt.plot(X,train_accuracy_set,'ob--',label='Train Accuracy')\n",
        "    plt.plot(X,dev_accuracy_set,'or--',label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.ylabel('Accuracy(%)')\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(X,train_losses_set,'ob--',label='Train Loss')\n",
        "    plt.plot(X,dev_losses_set,'or--',label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(X,train_uncertainty_set,'ob--',label='Train Loss')\n",
        "    plt.plot(X,dev_uncertainty_set,'or--',label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.ylabel('Epsitemic Uncertainty')\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDj321_YBYHI",
        "outputId": "aa44e1e9-0cb6-4a6f-dc4c-a431d8e81363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my batch_loss:0.6754757761955261\n",
            "batch_epis_uncertainty:0.6904257535934448\n",
            "my batch_loss:0.6756528615951538\n",
            "batch_epis_uncertainty:0.6904394030570984\n",
            "my batch_loss:0.6864073276519775\n",
            "batch_epis_uncertainty:0.6910537481307983\n",
            "my batch_loss:0.6924782395362854\n",
            "batch_epis_uncertainty:0.690927267074585\n",
            "my batch_loss:0.6659243702888489\n",
            "batch_epis_uncertainty:0.6905658841133118\n",
            "my batch_loss:0.6685757637023926\n",
            "batch_epis_uncertainty:0.6911106705665588\n",
            "my batch_loss:0.6910408735275269\n",
            "batch_epis_uncertainty:0.6907455325126648\n",
            "my batch_loss:0.6840200424194336\n",
            "batch_epis_uncertainty:0.690031886100769\n",
            "my batch_loss:0.6833774447441101\n",
            "batch_epis_uncertainty:0.6891690492630005\n",
            "my batch_loss:0.6890801787376404\n",
            "batch_epis_uncertainty:0.6896067261695862\n",
            "my batch_loss:0.692340075969696\n",
            "batch_epis_uncertainty:0.6902782917022705\n",
            "my batch_loss:0.6918727159500122\n",
            "batch_epis_uncertainty:0.6899918913841248\n",
            "my batch_loss:0.6702067255973816\n",
            "batch_epis_uncertainty:0.690862238407135\n",
            "my batch_loss:0.6873812675476074\n",
            "batch_epis_uncertainty:0.6910389065742493\n",
            "my batch_loss:0.6677950024604797\n",
            "batch_epis_uncertainty:0.688347578048706\n",
            "my batch_loss:0.6926850080490112\n",
            "batch_epis_uncertainty:0.687590479850769\n",
            "my batch_loss:0.6865312457084656\n",
            "batch_epis_uncertainty:0.6884762644767761\n",
            "my batch_loss:0.6674580574035645\n",
            "batch_epis_uncertainty:0.6878193616867065\n",
            "my batch_loss:0.6865366697311401\n",
            "batch_epis_uncertainty:0.6863242387771606\n",
            "my batch_loss:0.671088457107544\n",
            "batch_epis_uncertainty:0.6878709197044373\n",
            "my batch_loss:0.6749955415725708\n",
            "batch_epis_uncertainty:0.6859543323516846\n",
            "my batch_loss:0.6751721501350403\n",
            "batch_epis_uncertainty:0.6878753304481506\n",
            "my batch_loss:0.681271493434906\n",
            "batch_epis_uncertainty:0.6866753697395325\n",
            "my batch_loss:0.6859856247901917\n",
            "batch_epis_uncertainty:0.6884967088699341\n",
            "my batch_loss:0.6925145387649536\n",
            "batch_epis_uncertainty:0.6903420686721802\n",
            "my batch_loss:0.6782482266426086\n",
            "batch_epis_uncertainty:0.6900657415390015\n",
            "my batch_loss:0.6685387492179871\n",
            "batch_epis_uncertainty:0.689135730266571\n",
            "my batch_loss:0.6675539612770081\n",
            "batch_epis_uncertainty:0.6893093585968018\n",
            "my batch_loss:0.6630826592445374\n",
            "batch_epis_uncertainty:0.6893271207809448\n",
            "my batch_loss:0.6863296031951904\n",
            "batch_epis_uncertainty:0.6886659264564514\n",
            "my batch_loss:0.6762083768844604\n",
            "batch_epis_uncertainty:0.6893609762191772\n",
            "my batch_loss:0.6588439345359802\n",
            "batch_epis_uncertainty:0.6879401803016663\n",
            "my batch_loss:0.6728650331497192\n",
            "batch_epis_uncertainty:0.6871821880340576\n",
            "my batch_loss:0.686370849609375\n",
            "batch_epis_uncertainty:0.6864847540855408\n",
            "my batch_loss:0.7137146592140198\n",
            "batch_epis_uncertainty:0.6863803267478943\n",
            "my batch_loss:0.684150218963623\n",
            "batch_epis_uncertainty:0.6855512857437134\n",
            "my batch_loss:0.6793971657752991\n",
            "batch_epis_uncertainty:0.6874210834503174\n",
            "my batch_loss:0.6989976763725281\n",
            "batch_epis_uncertainty:0.6858969330787659\n",
            "my batch_loss:0.6649149656295776\n",
            "batch_epis_uncertainty:0.6875816583633423\n",
            "my batch_loss:0.6637502312660217\n",
            "batch_epis_uncertainty:0.6878959536552429\n",
            "my batch_loss:0.6910271644592285\n",
            "batch_epis_uncertainty:0.6885017156600952\n",
            "my batch_loss:0.6907405257225037\n",
            "batch_epis_uncertainty:0.6885710954666138\n",
            "my batch_loss:0.6705820560455322\n",
            "batch_epis_uncertainty:0.687040388584137\n",
            "my batch_loss:0.6739005446434021\n",
            "batch_epis_uncertainty:0.6854924559593201\n",
            "my batch_loss:0.6802446246147156\n",
            "batch_epis_uncertainty:0.6879319548606873\n",
            "Epoch: 1/5 Training Loss: 0.6801 Training Uncertainty: 0.6886 Training Accuracy: 57.8267%\n",
            "my batch_loss:0.6754150986671448\n",
            "batch_epis_uncertainty:0.6842235326766968\n",
            "my batch_loss:0.6653932332992554\n",
            "batch_epis_uncertainty:0.6817105412483215\n",
            "my batch_loss:0.692927360534668\n",
            "batch_epis_uncertainty:0.6872124671936035\n",
            "my batch_loss:0.6971253752708435\n",
            "batch_epis_uncertainty:0.6820958852767944\n",
            "my batch_loss:0.6590012907981873\n",
            "batch_epis_uncertainty:0.6810919046401978\n",
            "my batch_loss:0.6639352440834045\n",
            "batch_epis_uncertainty:0.6828631162643433\n",
            "my batch_loss:0.6816767454147339\n",
            "batch_epis_uncertainty:0.6853373646736145\n",
            "my batch_loss:0.6679434776306152\n",
            "batch_epis_uncertainty:0.6872878670692444\n",
            "my batch_loss:0.6854948401451111\n",
            "batch_epis_uncertainty:0.6866644620895386\n",
            "my batch_loss:0.6894850730895996\n",
            "batch_epis_uncertainty:0.6877531409263611\n",
            "my batch_loss:0.6711357235908508\n",
            "batch_epis_uncertainty:0.686471164226532\n",
            "my batch_loss:0.6544429063796997\n",
            "batch_epis_uncertainty:0.6884299516677856\n",
            "my batch_loss:0.6713360548019409\n",
            "batch_epis_uncertainty:0.6884235739707947\n",
            "my batch_loss:0.664295494556427\n",
            "batch_epis_uncertainty:0.6875147819519043\n",
            "my batch_loss:0.658338189125061\n",
            "batch_epis_uncertainty:0.6852784752845764\n",
            "my batch_loss:0.6507562398910522\n",
            "batch_epis_uncertainty:0.6855944991111755\n",
            "my batch_loss:0.6535857915878296\n",
            "batch_epis_uncertainty:0.6849703788757324\n",
            "my batch_loss:0.6642484664916992\n",
            "batch_epis_uncertainty:0.6851320862770081\n",
            "my batch_loss:0.6810287237167358\n",
            "batch_epis_uncertainty:0.6823977828025818\n",
            "my batch_loss:0.6468891501426697\n",
            "batch_epis_uncertainty:0.682794988155365\n",
            "my batch_loss:0.6464326977729797\n",
            "batch_epis_uncertainty:0.6809764504432678\n",
            "my batch_loss:0.6681393980979919\n",
            "batch_epis_uncertainty:0.682023823261261\n",
            "my batch_loss:0.6750824451446533\n",
            "batch_epis_uncertainty:0.6826589107513428\n",
            "my batch_loss:0.6635905504226685\n",
            "batch_epis_uncertainty:0.6796382069587708\n",
            "my batch_loss:0.6289266347885132\n",
            "batch_epis_uncertainty:0.6749468445777893\n",
            "my batch_loss:0.7201018929481506\n",
            "batch_epis_uncertainty:0.6788288354873657\n",
            "my batch_loss:0.7180917859077454\n",
            "batch_epis_uncertainty:0.679958164691925\n",
            "my batch_loss:0.7039594054222107\n",
            "batch_epis_uncertainty:0.6834436655044556\n",
            "my batch_loss:0.6687778234481812\n",
            "batch_epis_uncertainty:0.6847317218780518\n",
            "my batch_loss:0.6793243885040283\n",
            "batch_epis_uncertainty:0.6860213279724121\n",
            "my batch_loss:0.6531256437301636\n",
            "batch_epis_uncertainty:0.6866292357444763\n",
            "my batch_loss:0.6651278138160706\n",
            "batch_epis_uncertainty:0.6862457990646362\n",
            "my batch_loss:0.6550766825675964\n",
            "batch_epis_uncertainty:0.6871863603591919\n",
            "my batch_loss:0.6348943710327148\n",
            "batch_epis_uncertainty:0.6821112036705017\n",
            "my batch_loss:0.6699538826942444\n",
            "batch_epis_uncertainty:0.6849485635757446\n",
            "my batch_loss:0.6662189364433289\n",
            "batch_epis_uncertainty:0.6857177019119263\n",
            "my batch_loss:0.6529121994972229\n",
            "batch_epis_uncertainty:0.6818230152130127\n",
            "my batch_loss:0.6463810801506042\n",
            "batch_epis_uncertainty:0.6792430877685547\n",
            "my batch_loss:0.6815686225891113\n",
            "batch_epis_uncertainty:0.6806554198265076\n",
            "my batch_loss:0.6625722050666809\n",
            "batch_epis_uncertainty:0.6804949641227722\n",
            "my batch_loss:0.6453579068183899\n",
            "batch_epis_uncertainty:0.6773649454116821\n",
            "my batch_loss:0.6671893000602722\n",
            "batch_epis_uncertainty:0.6809082627296448\n",
            "my batch_loss:0.6567030549049377\n",
            "batch_epis_uncertainty:0.6745455265045166\n",
            "my batch_loss:0.6760620474815369\n",
            "batch_epis_uncertainty:0.6775000691413879\n",
            "my batch_loss:0.6456137895584106\n",
            "batch_epis_uncertainty:0.6714190244674683\n",
            "Epoch: 2/5 Training Loss: 0.6677 Training Uncertainty: 0.6830 Training Accuracy: 60.5521%\n",
            "my batch_loss:0.6588085889816284\n",
            "batch_epis_uncertainty:0.6785145998001099\n",
            "my batch_loss:0.6773324012756348\n",
            "batch_epis_uncertainty:0.6754058003425598\n",
            "my batch_loss:0.6784548759460449\n",
            "batch_epis_uncertainty:0.6767642498016357\n",
            "my batch_loss:0.6975498199462891\n",
            "batch_epis_uncertainty:0.6787391901016235\n",
            "my batch_loss:0.6694413423538208\n",
            "batch_epis_uncertainty:0.6817677021026611\n",
            "my batch_loss:0.6661771535873413\n",
            "batch_epis_uncertainty:0.6782523393630981\n",
            "my batch_loss:0.689896285533905\n",
            "batch_epis_uncertainty:0.6809594035148621\n",
            "my batch_loss:0.6598362326622009\n",
            "batch_epis_uncertainty:0.6823163032531738\n",
            "my batch_loss:0.657264769077301\n",
            "batch_epis_uncertainty:0.6821917295455933\n",
            "my batch_loss:0.6681446433067322\n",
            "batch_epis_uncertainty:0.6814131140708923\n",
            "my batch_loss:0.640596866607666\n",
            "batch_epis_uncertainty:0.6836450099945068\n",
            "my batch_loss:0.6543713212013245\n",
            "batch_epis_uncertainty:0.6824662089347839\n",
            "my batch_loss:0.6725507378578186\n",
            "batch_epis_uncertainty:0.6847772598266602\n",
            "my batch_loss:0.6495585441589355\n",
            "batch_epis_uncertainty:0.6823916435241699\n",
            "my batch_loss:0.655730664730072\n",
            "batch_epis_uncertainty:0.6824724078178406\n",
            "my batch_loss:0.6917830109596252\n",
            "batch_epis_uncertainty:0.6815443634986877\n",
            "my batch_loss:0.6692334413528442\n",
            "batch_epis_uncertainty:0.6819854378700256\n",
            "my batch_loss:0.6870906949043274\n",
            "batch_epis_uncertainty:0.6826074719429016\n",
            "my batch_loss:0.6533867716789246\n",
            "batch_epis_uncertainty:0.6821752786636353\n",
            "my batch_loss:0.6654385328292847\n",
            "batch_epis_uncertainty:0.6808472871780396\n",
            "my batch_loss:0.6334195137023926\n",
            "batch_epis_uncertainty:0.6812589168548584\n",
            "my batch_loss:0.6529403328895569\n",
            "batch_epis_uncertainty:0.6834889650344849\n",
            "my batch_loss:0.6529315114021301\n",
            "batch_epis_uncertainty:0.6812934875488281\n",
            "my batch_loss:0.6413944959640503\n",
            "batch_epis_uncertainty:0.6827993988990784\n",
            "my batch_loss:0.6673564314842224\n",
            "batch_epis_uncertainty:0.6864649057388306\n"
          ]
        }
      ],
      "source": [
        "# model epistemic uncertainty\n",
        "trained_model = train_epistemic(num_epochs=num_epochs, model=model_epis, train_dataloader=train_loader, dev_dataloader=val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug07AM2fO33i",
        "outputId": "721eac75-9842-4ca2-b0ab-0cd52013ed85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n"
          ]
        }
      ],
      "source": [
        "# # for test\n",
        "# for i, (batch_input_ids, batch_atten, batch_labels) in enumerate(train_loader):\n",
        "#   golden_labels = batch_labels.view(-1,1)\n",
        "#   y_hat = torch.zeros(batch_size, num_classes_)\n",
        "#   y_hat = y_hat.scatter(1, golden_labels, 1)\n",
        "#   print(y_hat.size(0))\n",
        "#   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNE1aV4Q-mDz"
      },
      "outputs": [],
      "source": [
        "def predict_nn(trained_model, test_loader):\n",
        "\n",
        "    trained_model.eval() # Switch model to evaluation mode \n",
        "    trained_model.apply(apply_dropout) # Keep the dropout layer open when testing\n",
        "\n",
        "    correct = 0  # count the number of correct classification labels\n",
        "\n",
        "    gold_labs = []  # gold labels to return\n",
        "    pred_labs = []  # predicted labels to return\n",
        "\n",
        "    for inputs, atten, labels in test_loader:\n",
        "      test_prob_total = torch.zeros((5, labels.size(0), num_classes_))\n",
        "      for i in range(5):\n",
        "        test_mu = trained_model(inputs, atten)\n",
        "        test_prob_total[i]=F.softmax(test_mu, dim=1)\n",
        "      test_prob_avg = torch.mean(test_prob_total, 0)\n",
        "      \n",
        "      # take the label with biggest output as the predicted label\n",
        "      predicted_labels = torch.max(test_prob_avg, 1)[1].data.numpy()\n",
        "\n",
        "      gold_labs.extend(labels.tolist())\n",
        "      pred_labs.extend(predicted_labels.tolist())\n",
        "    \n",
        "    return gold_labs, pred_labs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfx0KQF2Fozs"
      },
      "outputs": [],
      "source": [
        "gold_labs, pred_labs = predict_nn(trained_model, test_loader)\n",
        "\n",
        "# classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "target_names = ['not irony', 'irony']\n",
        "print(\"The classification report is:\")\n",
        "print(classification_report(gold_labs, pred_labs,target_names=target_names))\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(gold_labs, pred_labs)\n",
        "df_cm = pd.DataFrame(cm, index=target_names, columns=target_names)\n",
        "print(\"The confusion matrix is:\")\n",
        "print(df_cm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0993f5ff72d04b4ab5c840cac074e786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d0fc4caed6041d39b4c8f57b0c6dc5d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95b5aabde8f5497c8930695ab3bd4a7c",
            "value": 1
          }
        },
        "4b365143a5fc446fa674e14944c75fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d0fc4caed6041d39b4c8f57b0c6dc5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bdf383fd81e4cc48af920529b80ce31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef4032ca64549e49e5d03524202e882": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1c67c368b34a03bc23f39b5b9779b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b5aabde8f5497c8930695ab3bd4a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a43008a5558c429abf86ab5fd5317c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7093d323fb64902b877b687871c5fee",
              "IPY_MODEL_0993f5ff72d04b4ab5c840cac074e786",
              "IPY_MODEL_c07d6bdded8349469579f919c754fc07"
            ],
            "layout": "IPY_MODEL_4b365143a5fc446fa674e14944c75fdb"
          }
        },
        "b7093d323fb64902b877b687871c5fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82ba162b98741ee819231c8008e4058",
            "placeholder": "​",
            "style": "IPY_MODEL_6bdf383fd81e4cc48af920529b80ce31",
            "value": "100%"
          }
        },
        "c07d6bdded8349469579f919c754fc07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef4032ca64549e49e5d03524202e882",
            "placeholder": "​",
            "style": "IPY_MODEL_7e1c67c368b34a03bc23f39b5b9779b3",
            "value": " 1/1 [00:00&lt;00:00,  4.68ba/s]"
          }
        },
        "c82ba162b98741ee819231c8008e4058": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
